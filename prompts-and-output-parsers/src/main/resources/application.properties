# Ollama configuration
ollama.base-url=http://localhost:11434
ollama.model-name=llama2

# Configure logging
logging.level.org.springframework.ai=DEBUG
logging.level.dev.langchain4j=DEBUG
logging.level.habuma.springaiessentialexample=DEBUG
